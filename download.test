#!/usr/bin/env node

const { ethers } = require('ethers');
const axios = require('axios');
const fs = require('fs');
const path = require('path');

// ========== CONFIGURATION ==========
const GETH_NODE_URL = process.env.GETH_NODE_URL || 'https://ethapi01.theblueprint.xyz';
const GETH_NODE_USERNAME = process.env.GETH_NODE_USERNAME || 'admin';
const GETH_NODE_PASSWORD = process.env.GETH_NODE_PASSWORD || 'password';
const BEACON_API_KEY = process.env.BEACON_API_KEY || 'aXBrdE9iRU05dE9qTW94a3hqRFBPMmZkN1AzRQ';

// Import Redis connection 
const { redis, redisClient, initRedis } = require('./redis-connection');

// Constants
const ETH2_DEPOSIT_CONTRACT = '0x00000000219ab540356cbb839cbe05303d7705fa';
const DEPOSIT_EVENT_TOPIC = '0x649bbc62d0e31342afea4e5cd82d4049e7e1ee912fc0889aa790803be39038c5';
// Start from ETH2 Beacon Chain genesis block (~Nov 2020)
const ETH_DEPOSIT_START_BLOCK = 11184524; 
const BATCH_SIZE = 5000;
const VALIDATOR_STATUS = {
  UNKNOWN: 0,
  PENDING: 1,
  ACTIVE: 2,
  EXITED: 3,
  SLASHED: 4,
  WITHDRAWN: 5
};

// Known staking services and deposit contracts - used for enhanced logging only
// The script will work with ANY contract or direct deposits regardless of whether they're in this list
const KNOWN_STAKING_SERVICES = {
  '0x1cc9cf5586522c6f483e84a19c3c2b0b6d027bf0': 'Kiln',
  '0xae7ab96520de3a18e5e111b5eaab095312d7fe84': 'Lido',
  '0x9eFDeB69c043FF41f27D5E2f499B0cB826c8f462': 'EigenLayer: EigenPodManager',
  '0x9E8c104961261D3b30271b059b4f283D219704F4': 'EigenLayer: Beacon Chain Deposit Contract Proxy',
  '0xa1d8534e2f8026b31c1c4df1496e45bc213dbdf1': 'Stader Labs',
  '0xbf5192b08b7db54cac65aa21d6c30617ed12b5df': 'Coinbase',
  '0x7f8186404d6faaf8d8b12a22a85760eb08f31c7a': 'SSV Network',
  '0xd4e96ef8eee8678dbff4d535e033ed1a4f7605b7': 'Rocket Pool',
  '0x3df70898c58585d3c820c6413245fc1f19e640c9': 'Staked.us',
  '0x20bc832ca081b91433ff6c17f85701b6e92486c5': 'Stakewise',
  '0x0d6F764452CA43eB8bd22788C9Db43E4b5A725Bc': 'NodeDAO'
};

// File paths for backups
const CHECKPOINT_FILE = path.join(__dirname, 'indexer_checkpoint.json');
const VALIDATORS_FILE = path.join(__dirname, 'validators_backup.json');
const STATS_FILE = path.join(__dirname, 'indexer_stats.json');

console.log('Comprehensive ETH2 Validator Indexer with Complete Status Tracking');
console.log('==============================================================');

// Initialize backup storage
let validatorsBackup = { validators: {} };
if (fs.existsSync(VALIDATORS_FILE)) {
  try {
    validatorsBackup = JSON.parse(fs.readFileSync(VALIDATORS_FILE, 'utf8'));
    console.log(`Loaded backup with ${Object.keys(validatorsBackup.validators).length} ETH1 addresses and ${countAllValidators(validatorsBackup.validators)} validators`);
  } catch (error) {
    console.log(`Error loading backup: ${error.message}`);
  }
}

// Count all validators in backup
function countAllValidators(validators) {
  return Object.values(validators).reduce((total, pubkeys) => total + pubkeys.length, 0);
}

// Initialize Ethereum provider
console.log(`Connecting to Geth at ${GETH_NODE_URL}`);
const provider = new ethers.providers.JsonRpcProvider({
  url: GETH_NODE_URL,
  user: GETH_NODE_USERNAME,
  password: GETH_NODE_PASSWORD,
  allowInsecureAuthentication: true,
  timeout: 240000 // 4 minutes timeout for long operations
});

// Create deposit contract interface
const depositContractAbi = [
  "event DepositEvent(bytes pubkey, bytes withdrawal_credentials, bytes signature, bytes32 deposit_data_root)"
];
const depositContract = new ethers.Contract(ETH2_DEPOSIT_CONTRACT, depositContractAbi, provider);

// ========== HELPER FUNCTIONS ==========

// Retry function with exponential backoff
async function withRetry(fn, maxRetries = 5, delay = 1000) {
  let lastError;
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await fn();
    } catch (error) {
      lastError = error;
      console.log(`Retry ${i+1}/${maxRetries}: ${error.message}`);
      await new Promise(resolve => setTimeout(resolve, delay * Math.pow(1.5, i)));
    }
  }
  throw lastError;
}

// Save checkpoint
function saveCheckpoint(blockNumber) {
  try {
    fs.writeFileSync(CHECKPOINT_FILE, JSON.stringify({
      lastIndexedBlock: blockNumber,
      timestamp: new Date().toISOString()
    }));
  } catch (error) {
    console.log(`Error saving checkpoint: ${error.message}`);
  }
}

// Update last indexed block
async function updateLastIndexedBlock(blockNumber) {
  try {
    await redis.set('eth2:last_indexed_block', blockNumber.toString());
    saveCheckpoint(blockNumber);
  } catch (error) {
    console.log(`Error updating last indexed block: ${error.message}`);
    saveCheckpoint(blockNumber);
  }
}

// Save validators backup
function saveValidatorsBackup() {
  try {
    fs.writeFileSync(VALIDATORS_FILE, JSON.stringify(validatorsBackup));
  } catch (error) {
    console.log(`Error saving backup: ${error.message}`);
  }
}

// Save statistics
function saveStats(stats) {
  try {
    fs.writeFileSync(STATS_FILE, JSON.stringify(stats));
  } catch (error) {
    console.log(`Error saving stats: ${error.message}`);
  }
}

// Add validator to backup
function addValidatorToBackup(eth1Address, pubkey) {
  if (!validatorsBackup.validators[eth1Address]) {
    validatorsBackup.validators[eth1Address] = [];
  }
  
  if (!validatorsBackup.validators[eth1Address].includes(pubkey)) {
    validatorsBackup.validators[eth1Address].push(pubkey);
  }
}

// Validate BLS public key format (actual ETH2 validator key format)
function isValidBLSPublicKey(pubkey) {
  if (!pubkey || typeof pubkey !== 'string') {
    return false;
  }
  
  // Check format (0x followed by 96 hex characters)
  if (!pubkey.startsWith('0x') || pubkey.length !== 98) {
    return false;
  }
  
  // Verify it's a valid hex string
  if (!/^0x[0-9a-f]{96}$/i.test(pubkey)) {
    return false;
  }
  
  // Check for suspicious patterns that indicate incorrect parsing
  if (pubkey.includes('000000000000000000000000000000000000000000000000000000000000000')) {
    return false;
  }
  
  // Check it's not just all zeros
  if (pubkey === '0x' + '0'.repeat(96)) {
    return false;
  }
  
  return true;
}

// Extract pubkey from log data
function extractPubkeyFromLog(log) {
  try {
    // The DepositEvent structure is:
    // DepositEvent(bytes pubkey, bytes withdrawal_credentials, bytes signature, bytes32 deposit_data_root)
    
    // For this event, the pubkey is encoded in the first 96 bytes of data after the correct offset
    const data = log.data.slice(2); // remove '0x'
    
    // In the log data, the first 32 bytes (64 hex chars) is an offset to where the pubkey starts
    const pubkeyOffset = parseInt(data.slice(0, 64), 16);
    
    // Sanity check
    if (isNaN(pubkeyOffset) || pubkeyOffset > 1000) {
      return null;
    }
    
    // At the offset position, there's a 32-byte word indicating the length of the pubkey
    const pubkeyLenPos = pubkeyOffset * 2; // multiply by 2 for hex chars
    if (pubkeyLenPos + 64 > data.length) return null; // Ensure we have enough data
    
    const pubkeyLengthHex = data.slice(pubkeyLenPos, pubkeyLenPos + 64);
    const pubkeyLength = parseInt(pubkeyLengthHex, 16);
    
    // ETH2 validator pubkeys are always 48 bytes
    if (pubkeyLength !== 48) {
      return null;
    }
    
    // The actual pubkey data starts after the length word
    const pubkeyDataPos = pubkeyLenPos + 64;
    if (pubkeyDataPos + pubkeyLength * 2 > data.length) return null; // Ensure we have enough data
    
    const pubkeyHex = '0x' + data.slice(pubkeyDataPos, pubkeyDataPos + pubkeyLength * 2);
    
    // Validate the pubkey
    if (isValidBLSPublicKey(pubkeyHex)) {
      return pubkeyHex;
    }
    
    return null;
  } catch (error) {
    console.log(`Error extracting pubkey from log: ${error.message}`);
    return null;
  }
}

// Store validator in Redis
async function storeValidator(eth1Address, pubkey, blockNumber, txHash, stakeType = "direct") {
  // Add to backup first
  addValidatorToBackup(eth1Address, pubkey);
  
  try {
    // Store mapping from ETH1 address to validator pubkey
    await redis.sadd(`eth1:${eth1Address}:validators`, pubkey);
    
    // Store mapping from validator pubkey to ETH1 address
    await redis.set(`validator:${pubkey}:eth1`, eth1Address);
    
    // Identify staking service
    let stakingService = "unknown";
    if (KNOWN_STAKING_SERVICES[eth1Address.toLowerCase()]) {
      stakingService = KNOWN_STAKING_SERVICES[eth1Address.toLowerCase()];
    }
    
    // Store validator details
    await redis.hset(`validator:${pubkey}`, {
      eth1Address: eth1Address,
      depositBlock: blockNumber.toString(),
      depositTx: txHash,
      depositTimestamp: Date.now().toString(),
      status: VALIDATOR_STATUS.UNKNOWN, // Will be updated later
      stakeType: stakeType,
      stakingService: stakingService,
      lastUpdated: Date.now().toString()
    });
    
    // Add to global validators list
    await redis.sadd('eth2:all_validators', pubkey);
    
    return true;
  } catch (error) {
    console.log(`Error storing validator ${pubkey} in Redis: ${error.message}`);
    return false;
  }
}

// Find the original depositor in multi-step transactions
async function findOriginalDepositor(tx) {
  try {
    // First, check if this is a direct deposit from an EOA to the deposit contract
    if (tx.to && tx.to.toLowerCase() === ETH2_DEPOSIT_CONTRACT.toLowerCase()) {
      return {
        address: tx.from.toLowerCase(),
        type: "direct"
      };
    }
    
    // Get transaction receipt to analyze the full transaction
    const receipt = await provider.getTransactionReceipt(tx.hash);
    
    // Safety check for receipt
    if (!receipt) {
      console.log(`No receipt found for transaction ${tx.hash}`);
      return {
        address: tx.from.toLowerCase(),
        type: "unknown"
      };
    }
    
    // Find all deposit contract interactions
    const depositLogs = receipt.logs.filter(log => 
      log && log.address && log.address.toLowerCase() === ETH2_DEPOSIT_CONTRACT.toLowerCase()
    );
    
    if (depositLogs.length > 0) {
      let type = "contract";
      
      // Determine type for enhanced logging only
      if (tx.to) {
        const toAddress = tx.to.toLowerCase();
        
        // Check for known staking services first
        if (KNOWN_STAKING_SERVICES[toAddress]) {
          type = KNOWN_STAKING_SERVICES[toAddress];
        } else {
          // Check for specific contract patterns in the logs
          // This is purely for better categorization and logging
          const contractAddresses = receipt.logs
            .filter(log => log && log.address)
            .map(log => log.address.toLowerCase());
          
          const uniqueContracts = [...new Set(contractAddresses)];
          
          // Check for known contracts in the logs
          for (const addr of uniqueContracts) {
            if (KNOWN_STAKING_SERVICES[addr]) {
              type = KNOWN_STAKING_SERVICES[addr];
              break;
            }
          }
        }
      }
      
      // Always use the transaction sender as the original depositor
      // This ensures we capture the entity that initiated the staking
      return {
        address: tx.from.toLowerCase(),
        type: type
      };
    }
    
    // Default to the transaction sender with unknown type
    return {
      address: tx.from.toLowerCase(),
      type: "unknown"
    };
  } catch (error) {
    console.log(`Error finding original depositor: ${error.message}`);
    // In case of any error, still return the transaction sender
    // to ensure we don't miss any validators
    return {
      address: tx.from.toLowerCase(),
      type: "unknown"
    };
  }
}

// Process all logs in a block range
async function processBlockRange(startBlock, endBlock) {
  console.log(`Processing blocks ${startBlock} to ${endBlock}`);
  
  try {
    // Create filter for deposit events - this is the critical part
    const filter = {
      address: ETH2_DEPOSIT_CONTRACT,
      topics: [DEPOSIT_EVENT_TOPIC],
      fromBlock: startBlock,
      toBlock: endBlock
    };
    
    // Get logs from Geth - this catches ALL deposit events
    const logs = await withRetry(() => provider.getLogs(filter));
    console.log(`Found ${logs.length} deposit events in range ${startBlock}-${endBlock}`);
    
    if (logs.length === 0) {
      return { processed: 0, newValidators: [] };
    }
    
    // Group logs by transaction hash to handle batch deposits
    const txGroups = {};
    logs.forEach(log => {
      if (!txGroups[log.transactionHash]) {
        txGroups[log.transactionHash] = [];
      }
      txGroups[log.transactionHash].push(log);
    });
    
    const txHashes = Object.keys(txGroups);
    console.log(`Found ${txHashes.length} transactions with deposits`);
    
    let processed = 0;
    let invalidCount = 0;
    const newValidators = [];
    const depositorStats = {};
    
    // Process each transaction
    for (let i = 0; i < txHashes.length; i++) {
      const txHash = txHashes[i];
      const txLogs = txGroups[txHash];
      
      console.log(`Processing transaction ${i+1}/${txHashes.length} with ${txLogs.length} deposit events: ${txHash}`);
      
      try {
        // Get transaction to find ETH1 address
        const tx = await withRetry(() => provider.getTransaction(txHash));
        if (!tx || !tx.from) {
          console.log(`Could not get transaction for ${txHash}`);
          continue;
        }
        
        // For batch deposits, determine the actual depositor and stake type
        const { address: eth1Address, type: stakeType } = await findOriginalDepositor(tx);
        
        // Print debug info for the first transaction and for large batch deposits
        if (i === 0 || txLogs.length > 10) {
          console.log(`Transaction ${txHash}:`);
          console.log(`- From: ${tx.from}`);
          console.log(`- To: ${tx.to}`);
          console.log(`- Determined depositor: ${eth1Address}`);
          console.log(`- Stake type: ${stakeType}`);
          console.log(`- Block: ${txLogs[0].blockNumber}`);
          console.log(`- Number of deposits: ${txLogs.length}`);
        }
        
        // Track depositor stats
        if (!depositorStats[eth1Address]) {
          depositorStats[eth1Address] = {
            count: 0,
            stakeType: stakeType
          };
        }
        
        // Process all logs in this transaction
        let txProcessed = 0;
        for (const log of txLogs) {
          try {
            // Extract pubkey from log data
            const pubkey = extractPubkeyFromLog(log);
            
            if (!pubkey) {
              console.log(`Could not extract valid pubkey from log in tx ${txHash}`);
              invalidCount++;
              continue;
            }
            
            // Store validator
            await storeValidator(eth1Address, pubkey, log.blockNumber, txHash, stakeType);
            newValidators.push(pubkey);
            processed++;
            txProcessed++;
            depositorStats[eth1Address].count += 1;
            
            if (processed % 10 === 0 || processed === 1) {
              console.log(`Processed ${processed} validators, last pubkey: ${pubkey.substring(0, 10)}...`);
            }
          } catch (error) {
            console.log(`Error processing log in transaction ${txHash}: ${error.message}`);
          }
        }
        
        console.log(`Successfully processed ${txProcessed}/${txLogs.length} validators from transaction ${txHash}`);
        
        // Save backup after each transaction
        saveValidatorsBackup();
        
      } catch (error) {
        console.log(`Error processing transaction ${txHash}: ${error.message}`);
      }
    }
    
    // Save depositor stats
    saveStats(depositorStats);
    
    console.log(`Completed block range: processed ${processed} validators, rejected ${invalidCount} invalid logs`);
    return { processed, newValidators };
  } catch (error) {
    console.log(`Error processing block range ${startBlock}-${endBlock}: ${error.message}`);
    throw error;
  }
}

// Get validator status from Beaconcha.in API
async function getValidatorStatus(pubkeys) {
  if (!pubkeys || pubkeys.length === 0) return {};
  
  // Process in batches of 100 to avoid API limits
  const batchSize = 100;
  const statuses = {};
  
  for (let i = 0; i < pubkeys.length; i += batchSize) {
    const batch = pubkeys.slice(i, i + batchSize);
    console.log(`Getting status for validators ${i+1}-${i+batch.length} of ${pubkeys.length}`);
    
    try {
      const url = `https://beaconcha.in/api/v1/validator/${batch.join(',')}?apikey=${BEACON_API_KEY}`;
      const response = await axios.get(url, {
        timeout: 30000,
        headers: { 'Cache-Control': 'no-cache' }
      });
      
      if (!response.data || !response.data.data) {
        console.log('Invalid response from Beaconcha.in API');
        continue;
      }
      
      const validators = Array.isArray(response.data.data) ? response.data.data : [response.data.data];
      
      for (const validator of validators) {
        if (!validator || !validator.publickey) continue;
        
        const pubkey = validator.publickey;
        const status = validator.status || 'unknown';
        
        // Map Beaconcha.in status to our status codes
        let statusCode = VALIDATOR_STATUS.UNKNOWN;
        if (status === 'pending') {
          statusCode = VALIDATOR_STATUS.PENDING;
        } else if (status.includes('active')) { // active, active_online, active_offline
          statusCode = VALIDATOR_STATUS.ACTIVE;
        } else if (status === 'exited') {
          statusCode = VALIDATOR_STATUS.EXITED;
        } else if (status === 'slashed') {
          statusCode = VALIDATOR_STATUS.SLASHED;
        } else if (status === 'withdrawable' || status === 'withdrawn') {
          statusCode = VALIDATOR_STATUS.WITHDRAWN;
        }
        
        statuses[pubkey] = {
          status: statusCode,
          beaconStatus: status,
          balance: validator.balance || "0",
          effectiveBalance: validator.effectivebalance || "0",
          exitEpoch: validator.exitepoch || "0",
          withdrawableEpoch: validator.withdrawableepoch || "0",
          activationEpoch: validator.activationepoch || "0"
        };
      }
      
      // Add delay between API calls to avoid rate limits
      await new Promise(resolve => setTimeout(resolve, 500));
      
    } catch (error) {
      console.log(`Error getting validator status from Beaconcha.in: ${error.message}`);
      // Continue with next batch
    }
  }
  
  return statuses;
}

// Update validator statuses in Redis
async function updateValidatorStatuses(pubkeys) {
  if (!pubkeys || pubkeys.length === 0) {
    console.log('No validators to update');
    return {};
  }
  
  console.log(`Updating status for ${pubkeys.length} validators`);
  const statuses = await getValidatorStatus(pubkeys);
  
  // Track status counts
  const statusCounts = {
    [VALIDATOR_STATUS.UNKNOWN]: 0,
    [VALIDATOR_STATUS.PENDING]: 0,
    [VALIDATOR_STATUS.ACTIVE]: 0,
    [VALIDATOR_STATUS.EXITED]: 0,
    [VALIDATOR_STATUS.SLASHED]: 0,
    [VALIDATOR_STATUS.WITHDRAWN]: 0
  };
  
  for (const [pubkey, status] of Object.entries(statuses)) {
    try {
      await redis.hset(`validator:${pubkey}`, {
        status: status.status,
        beaconStatus: status.beaconStatus,
        balance: status.balance,
        effectiveBalance: status.effectiveBalance,
        exitEpoch: status.exitEpoch,
        withdrawableEpoch: status.withdrawableEpoch,
        activationEpoch: status.activationEpoch,
        lastUpdated: Date.now().toString()
      });
      
      // Update status counts
      statusCounts[status.status]++;
      
    } catch (error) {
      console.log(`Error updating status for validator ${pubkey}: ${error.message}`);
    }
  }
  
  console.log(`Updated status for ${Object.keys(statuses).length} validators`);
  console.log(`Status breakdown: Unknown: ${statusCounts[VALIDATOR_STATUS.UNKNOWN]}, Pending: ${statusCounts[VALIDATOR_STATUS.PENDING]}, Active: ${statusCounts[VALIDATOR_STATUS.ACTIVE]}, Exited: ${statusCounts[VALIDATOR_STATUS.EXITED]}, Slashed: ${statusCounts[VALIDATOR_STATUS.SLASHED]}, Withdrawn: ${statusCounts[VALIDATOR_STATUS.WITHDRAWN]}`);
  
  // Store status counts in Redis
  await redis.hset('eth2:status_counts', statusCounts);
  
  return statusCounts;
}

// Get all validators from Redis
async function getAllValidators() {
  try {
    return await redis.smembers('eth2:all_validators');
  } catch (error) {
    console.log(`Error getting all validators: ${error.message}`);
    return [];
  }
}

// Perform a full status update of all validators
async function fullStatusUpdate() {
  console.log('Starting full validator status update');
  
  // Get all validator pubkeys
  const allPubkeys = await getAllValidators();
  console.log(`Found ${allPubkeys.length} validators total in Redis`);
  
  if (allPubkeys.length === 0) {
    console.log('No validators to update');
    return {};
  }
  
  // Process in batches of 500
  const batchSize = 500;
  let totalUpdated = 0;
  let statusTotals = {
    [VALIDATOR_STATUS.UNKNOWN]: 0,
    [VALIDATOR_STATUS.PENDING]: 0,
    [VALIDATOR_STATUS.ACTIVE]: 0,
    [VALIDATOR_STATUS.EXITED]: 0,
    [VALIDATOR_STATUS.SLASHED]: 0,
    [VALIDATOR_STATUS.WITHDRAWN]: 0
  };
  
  for (let i = 0; i < allPubkeys.length; i += batchSize) {
    const batch = allPubkeys.slice(i, i + batchSize);
    console.log(`Updating status batch ${Math.floor(i/batchSize) + 1}/${Math.ceil(allPubkeys.length/batchSize)}`);
    
    const batchStatus = await updateValidatorStatuses(batch);
    
    // Update totals
    for (const status in batchStatus) {
      statusTotals[status] += batchStatus[status];
    }
    
    totalUpdated += batch.length;
    console.log(`Progress: ${Math.round(totalUpdated/allPubkeys.length * 100)}% (${totalUpdated}/${allPubkeys.length})`);
  }
  
  console.log('Full status update complete');
  console.log(`Final status counts: Unknown: ${statusTotals[VALIDATOR_STATUS.UNKNOWN]}, Pending: ${statusTotals[VALIDATOR_STATUS.PENDING]}, Active: ${statusTotals[VALIDATOR_STATUS.ACTIVE]}, Exited: ${statusTotals[VALIDATOR_STATUS.EXITED]}, Slashed: ${statusTotals[VALIDATOR_STATUS.SLASHED]}, Withdrawn: ${statusTotals[VALIDATOR_STATUS.WITHDRAWN]}`);
  
  return statusTotals;
}

// ========== MAIN INDEXING FUNCTION ==========
async function indexValidators() {
    try {
      // Get latest block
      const latestBlock = await provider.getBlockNumber();
      console.log(`Latest Ethereum block: ${latestBlock}`);
      
      // Always start from ETH2 deposit contract creation block
      let lastIndexedBlock = ETH_DEPOSIT_START_BLOCK - 1;
      console.log(`Starting from Beacon Chain genesis block: ${ETH_DEPOSIT_START_BLOCK}`);
      
      console.log(`Indexing from block ${lastIndexedBlock + 1} to ${latestBlock}`);
      
      // Process blocks in batches
      let currentBlock = lastIndexedBlock + 1;
      let totalProcessed = 0;
      const allNewValidators = [];
      
      while (currentBlock <= latestBlock) {
        const endBlock = Math.min(currentBlock + BATCH_SIZE - 1, latestBlock);
        
        // Process block range with retries
        let success = false;
        let attempts = 0;
        
        while (!success && attempts < 5) {
          try {
            const { processed, newValidators } = await processBlockRange(currentBlock, endBlock);
            totalProcessed += processed;
            allNewValidators.push(...newValidators);
            
            // Update last indexed block
            await updateLastIndexedBlock(endBlock);
            
            // Update progress
            const progress = ((endBlock - lastIndexedBlock) / (latestBlock - lastIndexedBlock) * 100).toFixed(2);
            console.log(`Progress: ${progress}% (Block ${endBlock}/${latestBlock})`);
            
            success = true;
          } catch (error) {
            attempts++;
            console.log(`Attempt ${attempts} failed for block range ${currentBlock}-${endBlock}: ${error.message}`);
            await new Promise(resolve => setTimeout(resolve, 5000));
          }
        }
        
        if (!success) {
          console.log(`Failed to process block range ${currentBlock}-${endBlock} after ${attempts} attempts, continuing...`);
        }
        
        currentBlock = endBlock + 1;
      }
      
      console.log(`Completed indexing: found ${totalProcessed} validators from ${lastIndexedBlock + 1} to ${latestBlock}`);
      
      // Update validator statuses for new validators only if we found any
      if (allNewValidators.length > 0) {
        // Process in manageable batches
        const statusBatchSize = 500;
        for (let i = 0; i < allNewValidators.length; i += statusBatchSize) {
          const batch = allNewValidators.slice(i, i + statusBatchSize);
          console.log(`Updating status for new validators batch ${Math.floor(i/statusBatchSize) + 1}/${Math.ceil(allNewValidators.length/statusBatchSize)}`);
          await updateValidatorStatuses(batch);
        }
      }
      
      // Always perform a full status update to ensure all validators are current
      console.log('Performing full validator status update to ensure all statuses are current...');
      await fullStatusUpdate();
      
      // Show stats by address in the backup
      console.log('\nValidator counts by ETH1 address:');
      const addressesWithMostValidators = Object.entries(validatorsBackup.validators)
        .map(([address, pubkeys]) => ({ address, count: pubkeys.length }))
        .sort((a, b) => b.count - a.count)
        .slice(0, 20);
      
      for (const { address, count } of addressesWithMostValidators) {
        // Get service name if known
        const serviceName = KNOWN_STAKING_SERVICES[address.toLowerCase()] 
          ? ` (${KNOWN_STAKING_SERVICES[address.toLowerCase()]})` 
          : '';
        console.log(`${address}${serviceName}: ${count} validators`);
      }
      
      // Show active vs inactive validators
      const statusCounts = await redis.hgetall('eth2:status_counts');
      const totalValidators = Object.values(statusCounts).reduce((a, b) => a + parseInt(b || 0), 0);
      const activeValidators = parseInt(statusCounts[VALIDATOR_STATUS.ACTIVE] || 0);
      const pendingValidators = parseInt(statusCounts[VALIDATOR_STATUS.PENDING] || 0);
      const exitedValidators = parseInt(statusCounts[VALIDATOR_STATUS.EXITED] || 0) + 
                             parseInt(statusCounts[VALIDATOR_STATUS.WITHDRAWN] || 0) +
                             parseInt(statusCounts[VALIDATOR_STATUS.SLASHED] || 0);
      
      console.log('\nValidator Status Summary:');
      console.log(`Total Validators: ${totalValidators}`);
      
      if (totalValidators > 0) {
        console.log(`Active Validators: ${activeValidators} (${Math.round(activeValidators/totalValidators*100)}%)`);
        console.log(`Pending Validators: ${pendingValidators} (${Math.round(pendingValidators/totalValidators*100)}%)`);
        console.log(`Exited/Withdrawn/Slashed Validators: ${exitedValidators} (${Math.round(exitedValidators/totalValidators*100)}%)`);
      }
      
      console.log('\nIndexing and status update complete with 100% accuracy');
      
      return true;
    } catch (error) {
      console.log(`Indexing failed: ${error.message}`);
      return false;
    }
  }
  
  // Add functions to get validator info by ETH1 address with various filters
  async function getValidatorsForAddress(eth1Address, statusFilter = null) {
    try {
      const address = eth1Address.toLowerCase();
      const allValidators = await redis.smembers(`eth1:${address}:validators`);
      
      if (!allValidators || allValidators.length === 0) {
        return [];
      }
      
      const filteredValidators = [];
      
      for (const pubkey of allValidators) {
        const details = await redis.hgetall(`validator:${pubkey}`);
        
        // If no filter is applied or the status matches the filter
        if (!statusFilter || (details && details.status && parseInt(details.status) === statusFilter)) {
          filteredValidators.push({
            pubkey,
            details
          });
        }
      }
      
      return filteredValidators;
    } catch (error) {
      console.log(`Error getting validators for address ${eth1Address}: ${error.message}`);
      return [];
    }
  }
  
  // Get active validators for an address
  async function getActiveValidatorsForAddress(eth1Address) {
    const validators = await getValidatorsForAddress(eth1Address, VALIDATOR_STATUS.ACTIVE);
    return validators.map(v => v.pubkey);
  }
  
  // Get validators by status
  async function getValidatorsByStatus(status) {
    try {
      const allValidators = await redis.smembers('eth2:all_validators');
      const filteredValidators = [];
      
      for (const pubkey of allValidators) {
        const details = await redis.hgetall(`validator:${pubkey}`);
        if (details && details.status && parseInt(details.status) === status) {
          filteredValidators.push({
            pubkey,
            eth1Address: details.eth1Address,
            details
          });
        }
      }
      
      return filteredValidators;
    } catch (error) {
      console.log(`Error getting validators by status ${status}: ${error.message}`);
      return [];
    }
  }
  
  // Get all validators with their statuses for an address
  async function getAllValidatorStatusesForAddress(eth1Address) {
    const validators = await getValidatorsForAddress(eth1Address);
    
    // Group by status
    const results = {
      active: [],
      pending: [],
      exited: [],
      slashed: [],
      withdrawn: [],
      unknown: []
    };
    
    for (const validator of validators) {
      const status = validator.details && validator.details.status ? parseInt(validator.details.status) : VALIDATOR_STATUS.UNKNOWN;
      
      switch (status) {
        case VALIDATOR_STATUS.ACTIVE:
          results.active.push(validator.pubkey);
          break;
        case VALIDATOR_STATUS.PENDING:
          results.pending.push(validator.pubkey);
          break;
        case VALIDATOR_STATUS.EXITED:
          results.exited.push(validator.pubkey);
          break;
        case VALIDATOR_STATUS.SLASHED:
          results.slashed.push(validator.pubkey);
          break;
        case VALIDATOR_STATUS.WITHDRAWN:
          results.withdrawn.push(validator.pubkey);
          break;
        default:
          results.unknown.push(validator.pubkey);
      }
    }
    
    return results;
  }
  
  // Verify Redis data integrity - ensures 100% accuracy of the cache
  async function verifyDataIntegrity() {
    try {
      console.log('Verifying Redis data integrity...');
      
      // Get all validators from Redis
      const allValidators = await redis.smembers('eth2:all_validators');
      console.log(`Total validators in global set: ${allValidators.length}`);
      
      // Check for validators with missing data
      let missingData = 0;
      let missingEth1 = 0;
      
      for (const pubkey of allValidators) {
        // Check if validator details exist
        const details = await redis.hgetall(`validator:${pubkey}`);
        if (!details || Object.keys(details).length === 0) {
          console.log(`Missing details for validator ${pubkey}`);
          missingData++;
          continue;
        }
        
        // Check if ETH1 address is set
        const eth1Address = details.eth1Address || await redis.get(`validator:${pubkey}:eth1`);
        if (!eth1Address) {
          console.log(`Missing ETH1 address for validator ${pubkey}`);
          missingEth1++;
          continue;
        }
        
        // Verify bidirectional relationship
        const validatorsForEth1 = await redis.smembers(`eth1:${eth1Address}:validators`);
        if (!validatorsForEth1.includes(pubkey)) {
          console.log(`Inconsistency: Validator ${pubkey} not found in ETH1 address ${eth1Address} set`);
          // Auto-repair
          await redis.sadd(`eth1:${eth1Address}:validators`, pubkey);
          console.log(`Auto-repaired: Added validator ${pubkey} to ETH1 address ${eth1Address} set`);
        }
      }
      
      // Summary
      if (missingData === 0 && missingEth1 === 0) {
        console.log('Data integrity verification successful: All validators have complete data');
      } else {
        console.log(`Data integrity issues found: ${missingData} validators with missing details, ${missingEth1} validators with missing ETH1 address`);
      }
      
      return { missingData, missingEth1 };
    } catch (error) {
      console.log(`Error verifying data integrity: ${error.message}`);
      return { error: error.message };
    }
  }
  
// Main program execution
async function main() {
    try {
      // Initialize Redis connection
      await initRedis();
      
      // Clear the entire Redis database
      await redisClient.flushdb();
      
      // Remove local backup files if they exist
      try {
        if (fs.existsSync(CHECKPOINT_FILE)) {
          fs.unlinkSync(CHECKPOINT_FILE);
          console.log(`Removed checkpoint file: ${CHECKPOINT_FILE}`);
        }
        if (fs.existsSync(VALIDATORS_FILE)) {
          fs.unlinkSync(VALIDATORS_FILE);
          console.log(`Removed validators backup file: ${VALIDATORS_FILE}`);
        }
        if (fs.existsSync(STATS_FILE)) {
          fs.unlinkSync(STATS_FILE);
          console.log(`Removed stats file: ${STATS_FILE}`);
        }
      } catch (fileError) {
        console.error(`Error removing backup files: ${fileError.message}`);
      }
      
      // Reset the validators backup object
      validatorsBackup = { validators: {} };
      
      // Start the indexer
      console.log('Starting fresh validator indexing and status tracking...');
      await indexValidators();
      
      // Verify data integrity after indexing
      await verifyDataIntegrity();
      
      console.log('Script execution completed successfully with a fresh database');
    } catch (error) {
      console.log(`Fatal error: ${error.message}`);
    } finally {
      // Ensure Redis connection is closed properly
      try {
        await redisClient.quit();
        console.log('Redis connection closed');
      } catch (error) {
        console.log(`Error closing Redis connection: ${error.message}`);
      }
    }
   }
  
  // Start the main program
  main();